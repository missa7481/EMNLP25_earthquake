{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20486,
     "status": "ok",
     "timestamp": 1742516905497,
     "user": {
      "displayName": "Juan Li",
      "userId": "09851037422769647021"
     },
     "user_tz": 240
    },
    "id": "CST3MJJP6i0t",
    "outputId": "f9551732-66f4-462d-94b8-2a3b90476799"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def read_json_files_from_directory(input_directory):\n",
    "    \"\"\"Reads all JSON files from a directory and returns a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "    input_directory: The path to the directory containing the JSON files.\n",
    "\n",
    "    Returns:\n",
    "    A list of dictionaries, where each dictionary represents the data from a JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".json\"):\n",
    "            filepath = os.path.join(input_directory, filename)\n",
    "            with open(filepath, 'r') as f:\n",
    "                for line in f:\n",
    "                  try:\n",
    "                    tweet = json.loads(line)\n",
    "                    data.append(tweet)\n",
    "                  except json.JSONDecodeError as e:\n",
    "                    continue\n",
    "                    # print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "input_directory = \"2022-fukushima_filtered\"  # Replace with your directory path\n",
    "data = read_json_files_from_directory(input_directory)\n",
    "print(len(data))\n",
    "print(data[0])  # To see the output, run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1149779,
     "status": "ok",
     "timestamp": 1742515784129,
     "user": {
      "displayName": "Juan Li",
      "userId": "09851037422769647021"
     },
     "user_tz": 240
    },
    "id": "FIIK7hWz8PkM",
    "outputId": "f209f266-b726-4f3a-fa0e-08d73ab8b3c0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def download_images(data, output_directory):\n",
    "    \"\"\"Downloads images from 'unique_image_urls' and saves them to the output directory.\n",
    "\n",
    "    Args:\n",
    "        data: The list of dictionaries containing the data.\n",
    "        output_directory: The path to the directory where images will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    for item in data:\n",
    "        if 'unique_image_urls' in item:\n",
    "            for image_url in item['unique_image_urls']:\n",
    "                try:\n",
    "                    response = requests.get(image_url, stream=True)\n",
    "                    response.raise_for_status()  # Raise an exception for bad responses\n",
    "\n",
    "                    # Extract filename from URL\n",
    "                    parsed_url = urlparse(image_url)\n",
    "                    filename = os.path.basename(parsed_url.path)\n",
    "\n",
    "                    # Save image to output directory\n",
    "                    filepath = os.path.join(output_directory, filename)\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "                    success_count += 1\n",
    "                    # print(f\"Downloaded: {image_url} to {filepath}\")  # To see the output, run the code.\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    error_count += 1\n",
    "                    print(f\"Error downloading {image_url}: {e}\")\n",
    "\n",
    "\n",
    "    print(f\"Total images downloaded: {success_count}\")\n",
    "    print(f\"Total errors: {error_count}\")\n",
    "\n",
    "# Example usage:\n",
    "output_directory = \"2019-ridgecrest_filtered_images\"\n",
    "download_images(data, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 936308,
     "status": "ok",
     "timestamp": 1742517950160,
     "user": {
      "displayName": "Juan Li",
      "userId": "09851037422769647021"
     },
     "user_tz": 240
    },
    "id": "9SdkcHH4FQp9",
    "outputId": "de73fec5-6840-4465-da41-a96396969382"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import concurrent.futures\n",
    "\n",
    "def download_image(image_url, output_directory):\n",
    "    \"\"\"Downloads a single image and saves it to the output directory.\n",
    "\n",
    "    Args:\n",
    "        image_url: The URL of the image to download.\n",
    "        output_directory: The path to the directory where images will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Raise an exception for bad responses\n",
    "\n",
    "        # Extract filename from URL\n",
    "        parsed_url = urlparse(image_url)\n",
    "        filename = os.path.basename(parsed_url.path)\n",
    "\n",
    "        # Save image to output directory\n",
    "        filepath = os.path.join(output_directory, filename)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        # print(f\"Downloaded: {image_url} to {filepath}\")  # To see the output, run the code.\n",
    "        return True  # Indicate success\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {image_url}: {e}\")\n",
    "        return False  # Indicate failure\n",
    "\n",
    "\n",
    "def download_images_multithreaded(data, output_directory, max_workers=5):\n",
    "    \"\"\"Downloads images from 'unique_image_urls' using multi-threading.\n",
    "\n",
    "    Args:\n",
    "        data: The list of dictionaries containing the data.\n",
    "        output_directory: The path to the directory where images will be saved.\n",
    "        max_workers: The maximum number of worker threads to use.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for item in data:\n",
    "            if 'unique_image_urls' in item:\n",
    "                for image_url in item['unique_image_urls']:\n",
    "                    future = executor.submit(download_image, image_url, output_directory)\n",
    "                    futures.append(future)\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            if future.result():  # Check if download was successful\n",
    "                success_count += 1\n",
    "            else:\n",
    "                error_count += 1\n",
    "\n",
    "    print(f\"Total images downloaded: {success_count}\")\n",
    "    print(f\"Total errors: {error_count}\")\n",
    "\n",
    "# Example usage:\n",
    "output_directory = \"2022-fukushima_filtered_images\"\n",
    "download_images_multithreaded(data, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9774,
     "status": "ok",
     "timestamp": 1742518040558,
     "user": {
      "displayName": "Juan Li",
      "userId": "09851037422769647021"
     },
     "user_tz": 240
    },
    "id": "F2QTP1HtDXR2",
    "outputId": "59f050ee-5ee7-454c-eac1-e08786892fba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"2022-fukushima_filtered_images\"\n",
    "\n",
    "# Get a list of all files and directories in the specified path\n",
    "all_files = os.listdir(directory_path)\n",
    "\n",
    "# Filter out directories and only count files\n",
    "file_count = len([f for f in all_files if os.path.isfile(os.path.join(directory_path, f))])\n",
    "\n",
    "print(f\"The number of files in '{directory_path}' is: {file_count}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOceva70pUpUsM7hDo0UDhh",
   "mount_file_id": "1ms9G-AoyxM7XvKJfZRTXoQVBfxZ7vZR8",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
